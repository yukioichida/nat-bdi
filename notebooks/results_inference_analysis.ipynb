{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "pio.templates.default = \"simple_white\"\n",
    "\n",
    "from scienceworld import ScienceWorldEnv\n",
    "\n",
    "from sources.scienceworld import load_step_function, parse_observation\n",
    "from sources.agent import BDIAgent\n",
    "from sources.bdi_components.inference import NLIModel\n",
    "from sources.bdi_components.belief import State\n",
    "\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T08:50:08.293168Z",
     "end_time": "2023-10-09T08:50:08.400323Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "def preprocess_df(results_df):\n",
    "    results_df.loc[results_df[\"plans_pct\"] == 1, \"plans_pct\"] = 100\n",
    "    results_df.loc[results_df[\"plans_pct\"] == 2, \"plans_pct\"] = 25\n",
    "    results_df.loc[results_df[\"plans_pct\"] == 5, \"plans_pct\"] = 50\n",
    "    results_df.loc[results_df[\"plans_pct\"] == 7, \"plans_pct\"] = 75\n",
    "    results_df['rl_score'] = results_df['rl_score'] / 100\n",
    "    results_df['bdi_score'] = results_df['bdi_score'] / 100\n",
    "    results_df['final_score'] = results_df['final_score'] / 100\n",
    "    return results_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T08:50:08.363094Z",
     "end_time": "2023-10-09T08:50:08.400323Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-10-09T08:50:09.732372Z",
     "end_time": "2023-10-09T08:50:09.911360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['melt', 'find-non-living-thing']\n"
     ]
    },
    {
     "data": {
      "text/plain": "     num_bdi_actions  num_rl_actions  plan_found  variation  error  bdi_score  \\\n0                  0              50           0         21   True        0.0   \n1                  5              50           1         22   True        0.0   \n2                  3              50           1         23   True        0.0   \n3                  5              50           1         24   True        0.0   \n4                  2              50           1         25   True        0.0   \n..               ...             ...         ...        ...    ...        ...   \n247                9               0           1        295  False        1.0   \n248               11               0           1        296  False        1.0   \n249               11               0           1        297  False        1.0   \n250               11               0           1        298  False        1.0   \n251               11               0           1        299  False        1.0   \n\n     rl_score  final_score  complete  num_plans  plan_library_size  plans_pct  \\\n0        0.03         0.03     False          0                 24        100   \n1        0.05         0.05     False          2                 24        100   \n2        0.05         0.05     False          2                 24        100   \n3        0.05         0.05     False          3                 24        100   \n4        0.03         0.03     False          2                 24        100   \n..        ...          ...       ...        ...                ...        ...   \n247      0.00         1.00      True          3                 41        100   \n248      0.00         1.00      True          3                 41        100   \n249      0.00         1.00      True          3                 41        100   \n250      0.00         1.00      True          3                 41        100   \n251      0.00         1.00      True          3                 41        100   \n\n     eps                                    drrn_model_file  \\\n0    457  models/model_task1melt/model-steps56000-eps457.pt   \n1    457  models/model_task1melt/model-steps56000-eps457.pt   \n2    457  models/model_task1melt/model-steps56000-eps457.pt   \n3    457  models/model_task1melt/model-steps56000-eps457.pt   \n4    457  models/model_task1melt/model-steps56000-eps457.pt   \n..   ...                                                ...   \n247  242    models/models_task13/model-steps32000-eps242.pt   \n248  242    models/models_task13/model-steps32000-eps242.pt   \n249  242    models/models_task13/model-steps32000-eps242.pt   \n250  242    models/models_task13/model-steps32000-eps242.pt   \n251  242    models/models_task13/model-steps32000-eps242.pt   \n\n                                     nli_model                   task  \\\n0    gchhablani/bert-base-cased-finetuned-mnli                   melt   \n1    gchhablani/bert-base-cased-finetuned-mnli                   melt   \n2    gchhablani/bert-base-cased-finetuned-mnli                   melt   \n3    gchhablani/bert-base-cased-finetuned-mnli                   melt   \n4    gchhablani/bert-base-cased-finetuned-mnli                   melt   \n..                                         ...                    ...   \n247                         roberta-large-mnli  find-non-living-thing   \n248                         roberta-large-mnli  find-non-living-thing   \n249                         roberta-large-mnli  find-non-living-thing   \n250                         roberta-large-mnli  find-non-living-thing   \n251                         roberta-large-mnli  find-non-living-thing   \n\n     num_total_plans  num_common_plans  num_specific_plans  \n0                193               180                  13  \n1                193               180                  13  \n2                193               180                  13  \n3                193               180                  13  \n4                193               180                  13  \n..               ...               ...                 ...  \n247              210               180                  30  \n248              210               180                  30  \n249              210               180                  30  \n250              210               180                  30  \n251              210               180                  30  \n\n[252 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_bdi_actions</th>\n      <th>num_rl_actions</th>\n      <th>plan_found</th>\n      <th>variation</th>\n      <th>error</th>\n      <th>bdi_score</th>\n      <th>rl_score</th>\n      <th>final_score</th>\n      <th>complete</th>\n      <th>num_plans</th>\n      <th>plan_library_size</th>\n      <th>plans_pct</th>\n      <th>eps</th>\n      <th>drrn_model_file</th>\n      <th>nli_model</th>\n      <th>task</th>\n      <th>num_total_plans</th>\n      <th>num_common_plans</th>\n      <th>num_specific_plans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>50</td>\n      <td>0</td>\n      <td>21</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>0.03</td>\n      <td>0.03</td>\n      <td>False</td>\n      <td>0</td>\n      <td>24</td>\n      <td>100</td>\n      <td>457</td>\n      <td>models/model_task1melt/model-steps56000-eps457.pt</td>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>melt</td>\n      <td>193</td>\n      <td>180</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>50</td>\n      <td>1</td>\n      <td>22</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>False</td>\n      <td>2</td>\n      <td>24</td>\n      <td>100</td>\n      <td>457</td>\n      <td>models/model_task1melt/model-steps56000-eps457.pt</td>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>melt</td>\n      <td>193</td>\n      <td>180</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>50</td>\n      <td>1</td>\n      <td>23</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>False</td>\n      <td>2</td>\n      <td>24</td>\n      <td>100</td>\n      <td>457</td>\n      <td>models/model_task1melt/model-steps56000-eps457.pt</td>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>melt</td>\n      <td>193</td>\n      <td>180</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>50</td>\n      <td>1</td>\n      <td>24</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>False</td>\n      <td>3</td>\n      <td>24</td>\n      <td>100</td>\n      <td>457</td>\n      <td>models/model_task1melt/model-steps56000-eps457.pt</td>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>melt</td>\n      <td>193</td>\n      <td>180</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>50</td>\n      <td>1</td>\n      <td>25</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>0.03</td>\n      <td>0.03</td>\n      <td>False</td>\n      <td>2</td>\n      <td>24</td>\n      <td>100</td>\n      <td>457</td>\n      <td>models/model_task1melt/model-steps56000-eps457.pt</td>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>melt</td>\n      <td>193</td>\n      <td>180</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>247</th>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>295</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>True</td>\n      <td>3</td>\n      <td>41</td>\n      <td>100</td>\n      <td>242</td>\n      <td>models/models_task13/model-steps32000-eps242.pt</td>\n      <td>roberta-large-mnli</td>\n      <td>find-non-living-thing</td>\n      <td>210</td>\n      <td>180</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>296</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>True</td>\n      <td>3</td>\n      <td>41</td>\n      <td>100</td>\n      <td>242</td>\n      <td>models/models_task13/model-steps32000-eps242.pt</td>\n      <td>roberta-large-mnli</td>\n      <td>find-non-living-thing</td>\n      <td>210</td>\n      <td>180</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>249</th>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>297</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>True</td>\n      <td>3</td>\n      <td>41</td>\n      <td>100</td>\n      <td>242</td>\n      <td>models/models_task13/model-steps32000-eps242.pt</td>\n      <td>roberta-large-mnli</td>\n      <td>find-non-living-thing</td>\n      <td>210</td>\n      <td>180</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>250</th>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>298</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>True</td>\n      <td>3</td>\n      <td>41</td>\n      <td>100</td>\n      <td>242</td>\n      <td>models/models_task13/model-steps32000-eps242.pt</td>\n      <td>roberta-large-mnli</td>\n      <td>find-non-living-thing</td>\n      <td>210</td>\n      <td>180</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>251</th>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>299</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>True</td>\n      <td>3</td>\n      <td>41</td>\n      <td>100</td>\n      <td>242</td>\n      <td>models/models_task13/model-steps32000-eps242.pt</td>\n      <td>roberta-large-mnli</td>\n      <td>find-non-living-thing</td>\n      <td>210</td>\n      <td>180</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n<p>252 rows × 19 columns</p>\n</div>"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "plan_statistics = pd.read_csv(\"plan_statistics.csv\")\n",
    "\n",
    "dirs = [\"../results/v2-gchhablani-bert-base-cased-finetuned-mnli/\", \"../results/v2-MoritzLaurer-MiniLM-L6-mnli/\",\n",
    "        \"../results/v2-roberta-large-mnli/\"]  #, \"../results/v2-ynie-roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli/\"]\n",
    "#dirs = [\"../results/v2-minilm/\"]\n",
    "tasks = ['melt', 'find-non-living-thing']\n",
    "print(tasks)\n",
    "#files_overall = \"results_melt.csv\"\n",
    "#files_nli = \"results_nli_melt.csv\"\n",
    "\n",
    "all_overall_dfs = []\n",
    "all_nli_dfs = []\n",
    "for dir in dirs:\n",
    "    for task in tasks:\n",
    "        results_df = pd.read_csv(dir + f\"results_{task}.csv\")\n",
    "        results_df['task'] = task\n",
    "        all_overall_dfs.append(results_df)\n",
    "\n",
    "        nli_results_df = pd.read_csv(dir + f\"results_nli_{task}.csv\")\n",
    "        nli_results_df['task'] = task\n",
    "        all_nli_dfs.append(nli_results_df)\n",
    "\n",
    "overall_results_df = pd.concat(all_overall_dfs)\n",
    "overall_results_df = preprocess_df(overall_results_df)\n",
    "overall_results_df = pd.merge(overall_results_df, plan_statistics, on=['plans_pct', 'task'])\n",
    "overall_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "                    task  plans_pct  eps  num_specific_plans  \\\n2  find-non-living-thing        100  242                  30   \n1  find-non-living-thing        100  242                  30   \n0  find-non-living-thing        100  242                  30   \n5                   melt        100  457                  13   \n4                   melt        100  457                  13   \n3                   melt        100  457                  13   \n\n                                   nli_model  variation  final_score  \\\n2                         roberta-large-mnli         75     0.980000   \n1  gchhablani/bert-base-cased-finetuned-mnli         75     0.937200   \n0                MoritzLaurer/MiniLM-L6-mnli         75     0.885333   \n5                         roberta-large-mnli          9     0.676667   \n4  gchhablani/bert-base-cased-finetuned-mnli          9     0.362222   \n3                MoritzLaurer/MiniLM-L6-mnli          9     0.262222   \n\n   rl_score  bdi_score  num_bdi_actions  num_rl_actions     error  num_plans  \n2  0.000000   0.980000         9.186667        4.000000  0.080000   2.840000  \n1  0.094400   0.842800         9.613333       10.000000  0.200000   2.720000  \n0  0.196000   0.689333         7.653333       18.666667  0.373333   2.573333  \n5  0.003333   0.673333        20.888889       16.666667  0.333333   5.666667  \n4  0.028889   0.333333        11.444444       33.333333  0.666667   3.555556  \n3  0.028889   0.233333         8.777778       50.000000  1.000000   3.555556  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task</th>\n      <th>plans_pct</th>\n      <th>eps</th>\n      <th>num_specific_plans</th>\n      <th>nli_model</th>\n      <th>variation</th>\n      <th>final_score</th>\n      <th>rl_score</th>\n      <th>bdi_score</th>\n      <th>num_bdi_actions</th>\n      <th>num_rl_actions</th>\n      <th>error</th>\n      <th>num_plans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>find-non-living-thing</td>\n      <td>100</td>\n      <td>242</td>\n      <td>30</td>\n      <td>roberta-large-mnli</td>\n      <td>75</td>\n      <td>0.980000</td>\n      <td>0.000000</td>\n      <td>0.980000</td>\n      <td>9.186667</td>\n      <td>4.000000</td>\n      <td>0.080000</td>\n      <td>2.840000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>find-non-living-thing</td>\n      <td>100</td>\n      <td>242</td>\n      <td>30</td>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>75</td>\n      <td>0.937200</td>\n      <td>0.094400</td>\n      <td>0.842800</td>\n      <td>9.613333</td>\n      <td>10.000000</td>\n      <td>0.200000</td>\n      <td>2.720000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>find-non-living-thing</td>\n      <td>100</td>\n      <td>242</td>\n      <td>30</td>\n      <td>MoritzLaurer/MiniLM-L6-mnli</td>\n      <td>75</td>\n      <td>0.885333</td>\n      <td>0.196000</td>\n      <td>0.689333</td>\n      <td>7.653333</td>\n      <td>18.666667</td>\n      <td>0.373333</td>\n      <td>2.573333</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>melt</td>\n      <td>100</td>\n      <td>457</td>\n      <td>13</td>\n      <td>roberta-large-mnli</td>\n      <td>9</td>\n      <td>0.676667</td>\n      <td>0.003333</td>\n      <td>0.673333</td>\n      <td>20.888889</td>\n      <td>16.666667</td>\n      <td>0.333333</td>\n      <td>5.666667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>melt</td>\n      <td>100</td>\n      <td>457</td>\n      <td>13</td>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>9</td>\n      <td>0.362222</td>\n      <td>0.028889</td>\n      <td>0.333333</td>\n      <td>11.444444</td>\n      <td>33.333333</td>\n      <td>0.666667</td>\n      <td>3.555556</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>melt</td>\n      <td>100</td>\n      <td>457</td>\n      <td>13</td>\n      <td>MoritzLaurer/MiniLM-L6-mnli</td>\n      <td>9</td>\n      <td>0.262222</td>\n      <td>0.028889</td>\n      <td>0.233333</td>\n      <td>8.777778</td>\n      <td>50.000000</td>\n      <td>1.000000</td>\n      <td>3.555556</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected_cols = ['task', 'plans_pct', 'eps', 'num_specific_plans', 'nli_model']\n",
    "aggregations = {'variation': 'count', 'final_score': 'mean', 'rl_score': 'mean', 'bdi_score': 'mean',\n",
    "                'num_bdi_actions': 'mean', 'num_rl_actions': 'mean', 'error': 'mean', 'num_plans': 'mean'}\n",
    "\n",
    "grouped_df = overall_results_df.groupby(projected_cols).agg(aggregations).reset_index()\n",
    "grouped_df['dense_rank'] = (\n",
    "    grouped_df.groupby(['plans_pct', 'task', \"nli_model\"])['final_score'].rank(method='dense', ascending=False).astype(\n",
    "        int))\n",
    "\n",
    "#grouped_df = grouped_df.sort_values(['plans_pct', 'dense_rank'], ascending=[True, True]).reset_index()\n",
    "grouped_df = grouped_df[(grouped_df['dense_rank'] == 1)].sort_values([\"task\", \"num_specific_plans\", \"nli_model\"])\n",
    "# avoiding tied rows\n",
    "grouped_df.drop(columns=['dense_rank']).sort_values(by=['final_score', 'nli_model'], ascending=[False, False])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T08:50:10.508779Z",
     "end_time": "2023-10-09T08:50:10.572680Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "                    Task          Model     Score  BDI Score  Num Actions  \\\n0  find-non-living-thing      MiniLM L6  0.885333   0.689333     7.653333   \n1  find-non-living-thing      Bert Base  0.937200   0.842800     9.613333   \n2  find-non-living-thing  Roberta Large  0.980000   0.980000     9.186667   \n3                   melt      MiniLM L6  0.262222   0.233333     8.777778   \n4                   melt      Bert Base  0.362222   0.333333    11.444444   \n5                   melt  Roberta Large  0.676667   0.673333    20.888889   \n\n     Errors  Num Plans  \n0  0.373333   2.573333  \n1  0.200000   2.720000  \n2  0.080000   2.840000  \n3  1.000000   3.555556  \n4  0.666667   3.555556  \n5  0.333333   5.666667  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Task</th>\n      <th>Model</th>\n      <th>Score</th>\n      <th>BDI Score</th>\n      <th>Num Actions</th>\n      <th>Errors</th>\n      <th>Num Plans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>find-non-living-thing</td>\n      <td>MiniLM L6</td>\n      <td>0.885333</td>\n      <td>0.689333</td>\n      <td>7.653333</td>\n      <td>0.373333</td>\n      <td>2.573333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>find-non-living-thing</td>\n      <td>Bert Base</td>\n      <td>0.937200</td>\n      <td>0.842800</td>\n      <td>9.613333</td>\n      <td>0.200000</td>\n      <td>2.720000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>find-non-living-thing</td>\n      <td>Roberta Large</td>\n      <td>0.980000</td>\n      <td>0.980000</td>\n      <td>9.186667</td>\n      <td>0.080000</td>\n      <td>2.840000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>melt</td>\n      <td>MiniLM L6</td>\n      <td>0.262222</td>\n      <td>0.233333</td>\n      <td>8.777778</td>\n      <td>1.000000</td>\n      <td>3.555556</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>melt</td>\n      <td>Bert Base</td>\n      <td>0.362222</td>\n      <td>0.333333</td>\n      <td>11.444444</td>\n      <td>0.666667</td>\n      <td>3.555556</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>melt</td>\n      <td>Roberta Large</td>\n      <td>0.676667</td>\n      <td>0.673333</td>\n      <td>20.888889</td>\n      <td>0.333333</td>\n      <td>5.666667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_df = grouped_df.loc[:, ['task', 'nli_model', 'final_score', 'bdi_score', 'num_bdi_actions', 'error', 'num_plans']]\n",
    "write_df = write_df.replace('MoritzLaurer/MiniLM-L6-mnli', 'MiniLM L6')\n",
    "#write_df = write_df.replace('ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli', 'Roberta Large')\n",
    "write_df = write_df.replace('roberta-large-mnli', 'Roberta Large')\n",
    "write_df = write_df.replace('gchhablani/bert-base-cased-finetuned-mnli', 'Bert Base')\n",
    "write_df.rename(columns={\n",
    "    'task': 'Task',\n",
    "    'nli_model': 'Model',\n",
    "    'bdi_score': 'BDI Score',\n",
    "    'final_score': 'Score',\n",
    "    'error': 'Errors',\n",
    "    'num_plans': 'Num Plans',\n",
    "    'num_bdi_actions': 'Num Actions'\n",
    "}, inplace=True)\n",
    "\n",
    "write_df[['Task', 'Model', 'Score', 'BDI Score', 'Errors', 'Num Plans']].to_csv(\"nli_performance_results.csv\",\n",
    "                                                                                index=False, float_format='%.3f')\n",
    "write_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T08:50:11.304063Z",
     "end_time": "2023-10-09T08:50:11.333060Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_overlap(a, b):\n",
    "    words_doc1 = set(a.split())\n",
    "    words_doc2 = set(b.split())\n",
    "\n",
    "    diff = words_doc1.intersection(words_doc2)\n",
    "    return len(diff)\n",
    "\n",
    "lexical_overlap(\"you see a pot\", \"you see a container\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T08:50:54.626895Z",
     "end_time": "2023-10-09T08:50:54.681253Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5398\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                   p                   h  \\\n0             In your inventory, you see: an orange   you are in hallway   \n1               This room is called the living room.  you are in hallway   \n2                                  You see the agent  you are in hallway   \n3                     You see a substance called air  you are in hallway   \n4  You see a book shelf (containing A book (Frank...  you are in hallway   \n\n   output                                      model  task  \n0       2  gchhablani/bert-base-cased-finetuned-mnli  melt  \n1       2  gchhablani/bert-base-cased-finetuned-mnli  melt  \n2       2  gchhablani/bert-base-cased-finetuned-mnli  melt  \n3       2  gchhablani/bert-base-cased-finetuned-mnli  melt  \n4       2  gchhablani/bert-base-cased-finetuned-mnli  melt  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>p</th>\n      <th>h</th>\n      <th>output</th>\n      <th>model</th>\n      <th>task</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In your inventory, you see: an orange</td>\n      <td>you are in hallway</td>\n      <td>2</td>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>melt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This room is called the living room.</td>\n      <td>you are in hallway</td>\n      <td>2</td>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>melt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You see the agent</td>\n      <td>you are in hallway</td>\n      <td>2</td>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>melt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You see a substance called air</td>\n      <td>you are in hallway</td>\n      <td>2</td>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>melt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You see a book shelf (containing A book (Frank...</td>\n      <td>you are in hallway</td>\n      <td>2</td>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>melt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli_results_df = pd.concat(all_nli_dfs)\n",
    "print(len(nli_results_df))\n",
    "nli_results_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T08:50:58.329142Z",
     "end_time": "2023-10-09T08:50:58.362127Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoritzLaurer/MiniLM-L6-mnli\n",
      "gchhablani/bert-base-cased-finetuned-mnli\n",
      "roberta-large-mnli\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                   p                   h  \\\n0             In your inventory, you see: an orange   you are in hallway   \n1               This room is called the living room.  you are in hallway   \n2                                  You see the agent  you are in hallway   \n3                     You see a substance called air  you are in hallway   \n4  You see a book shelf (containing A book (Frank...  you are in hallway   \n\n   output                        model  task      inference  lexical_overlap  \\\n0       2  MoritzLaurer/MiniLM-L6-mnli  melt  contradiction                1   \n1       2  MoritzLaurer/MiniLM-L6-mnli  melt  contradiction                0   \n2       1  MoritzLaurer/MiniLM-L6-mnli  melt        neutral                0   \n3       2  MoritzLaurer/MiniLM-L6-mnli  melt  contradiction                0   \n4       2  MoritzLaurer/MiniLM-L6-mnli  melt  contradiction                0   \n\n   length_p  length_h  \n0         7         4  \n1         7         4  \n2         4         4  \n3         6         4  \n4        15         4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>p</th>\n      <th>h</th>\n      <th>output</th>\n      <th>model</th>\n      <th>task</th>\n      <th>inference</th>\n      <th>lexical_overlap</th>\n      <th>length_p</th>\n      <th>length_h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In your inventory, you see: an orange</td>\n      <td>you are in hallway</td>\n      <td>2</td>\n      <td>MoritzLaurer/MiniLM-L6-mnli</td>\n      <td>melt</td>\n      <td>contradiction</td>\n      <td>1</td>\n      <td>7</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This room is called the living room.</td>\n      <td>you are in hallway</td>\n      <td>2</td>\n      <td>MoritzLaurer/MiniLM-L6-mnli</td>\n      <td>melt</td>\n      <td>contradiction</td>\n      <td>0</td>\n      <td>7</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You see the agent</td>\n      <td>you are in hallway</td>\n      <td>1</td>\n      <td>MoritzLaurer/MiniLM-L6-mnli</td>\n      <td>melt</td>\n      <td>neutral</td>\n      <td>0</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You see a substance called air</td>\n      <td>you are in hallway</td>\n      <td>2</td>\n      <td>MoritzLaurer/MiniLM-L6-mnli</td>\n      <td>melt</td>\n      <td>contradiction</td>\n      <td>0</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You see a book shelf (containing A book (Frank...</td>\n      <td>you are in hallway</td>\n      <td>2</td>\n      <td>MoritzLaurer/MiniLM-L6-mnli</td>\n      <td>melt</td>\n      <td>contradiction</td>\n      <td>0</td>\n      <td>15</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "all_groups_df = []\n",
    "for model, group_df in nli_results_df.groupby(\"model\"):\n",
    "    print(model)\n",
    "    config = AutoConfig.from_pretrained(model)\n",
    "    #print(config.label2id)\n",
    "    #print(config.id2label)\n",
    "    group_df['inference'] = group_df['output'].apply(lambda id: config.id2label[id].lower())\n",
    "    all_groups_df.append(group_df)\n",
    "\n",
    "filtered_nli_df = pd.concat(all_groups_df)\n",
    "#filtered_nli_df['levenshtein_distance'] = filtered_nli_df.apply(lambda row: levenshtein_distance(row['p'], row['h']), axis=1)\n",
    "filtered_nli_df['lexical_overlap'] = filtered_nli_df.apply(lambda row: lexical_overlap(row['p'], row['h']), axis=1)\n",
    "filtered_nli_df['length_p'] = filtered_nli_df['p'].apply(lambda p: len(p.split()))\n",
    "filtered_nli_df['length_h'] = filtered_nli_df['h'].apply(lambda h: len(h.split()))\n",
    "\n",
    "filtered_nli_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T08:51:00.912270Z",
     "end_time": "2023-10-09T08:51:02.324309Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       model  num_entailment  \\\n0                MoritzLaurer/MiniLM-L6-mnli              25   \n1                MoritzLaurer/MiniLM-L6-mnli              23   \n2  gchhablani/bert-base-cased-finetuned-mnli              25   \n3  gchhablani/bert-base-cased-finetuned-mnli              25   \n4                         roberta-large-mnli              27   \n\n   num_nonentailment  num_inferences  mean_entailment_lexical_overlap  \\\n0               1051            1076                         0.640000   \n1                668             691                         1.347826   \n2               1050            1075                         0.600000   \n3                665             690                         1.160000   \n4               1049            1076                         0.407407   \n\n     mean_h     mean_p                   task  \n0  4.200000   7.840000  find-non-living-thing  \n1  4.826087  10.956522                   melt  \n2  4.160000   8.400000  find-non-living-thing  \n3  4.800000  11.120000                   melt  \n4  4.185185   7.296296  find-non-living-thing  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>num_entailment</th>\n      <th>num_nonentailment</th>\n      <th>num_inferences</th>\n      <th>mean_entailment_lexical_overlap</th>\n      <th>mean_h</th>\n      <th>mean_p</th>\n      <th>task</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MoritzLaurer/MiniLM-L6-mnli</td>\n      <td>25</td>\n      <td>1051</td>\n      <td>1076</td>\n      <td>0.640000</td>\n      <td>4.200000</td>\n      <td>7.840000</td>\n      <td>find-non-living-thing</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MoritzLaurer/MiniLM-L6-mnli</td>\n      <td>23</td>\n      <td>668</td>\n      <td>691</td>\n      <td>1.347826</td>\n      <td>4.826087</td>\n      <td>10.956522</td>\n      <td>melt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>25</td>\n      <td>1050</td>\n      <td>1075</td>\n      <td>0.600000</td>\n      <td>4.160000</td>\n      <td>8.400000</td>\n      <td>find-non-living-thing</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gchhablani/bert-base-cased-finetuned-mnli</td>\n      <td>25</td>\n      <td>665</td>\n      <td>690</td>\n      <td>1.160000</td>\n      <td>4.800000</td>\n      <td>11.120000</td>\n      <td>melt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>roberta-large-mnli</td>\n      <td>27</td>\n      <td>1049</td>\n      <td>1076</td>\n      <td>0.407407</td>\n      <td>4.185185</td>\n      <td>7.296296</td>\n      <td>find-non-living-thing</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_statistics = []\n",
    "for (model, task), group_df in filtered_nli_df.groupby([\"model\", \"task\"]):\n",
    "    all_statistics.append({\n",
    "        'model': model,\n",
    "        'num_entailment': len(group_df[group_df['inference'] == 'entailment']),\n",
    "        #'num_neutral': len(group_df[group_df['inference'] == 'neutral']),\n",
    "        #'num_contradiction': len(group_df[group_df['inference'] == 'contradiction']),\n",
    "        'num_nonentailment': len(group_df[group_df['inference'] == 'neutral']) + len(\n",
    "            group_df[group_df['inference'] == 'contradiction']),\n",
    "        'num_inferences': len(group_df),\n",
    "        'mean_entailment_lexical_overlap': group_df[group_df['inference'] == 'entailment']['lexical_overlap'].mean(),\n",
    "        'mean_h': group_df[group_df['inference'] == 'entailment']['length_h'].mean(),\n",
    "        'mean_p': group_df[group_df['inference'] == 'entailment']['length_p'].mean(),\n",
    "        \"task\": task\n",
    "    })\n",
    "\n",
    "statistics_df = pd.DataFrame(all_statistics)\n",
    "#full_models_df = pd.merge(statistics_df, on='model', how='inner')\n",
    "statistics_df = statistics_df  #.drop(columns=['num_entailment', 'num_nonentailment'])\n",
    "statistics_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T08:51:04.065095Z",
     "end_time": "2023-10-09T08:51:04.096119Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "                    Task          Model     LO(E)  Mean Plan Context  \\\n0  find-non-living-thing      MiniLM L6  0.640000           4.200000   \n1                   melt      MiniLM L6  1.347826           4.826087   \n2  find-non-living-thing      Bert Base  0.600000           4.160000   \n3                   melt      Bert Base  1.160000           4.800000   \n4  find-non-living-thing  Roberta Large  0.407407           4.185185   \n5                   melt  Roberta Large  1.218750           5.250000   \n\n   Mean Beliefs  Inferences  \n0      7.840000        1076  \n1     10.956522         691  \n2      8.400000        1075  \n3     11.120000         690  \n4      7.296296        1076  \n5     11.062500         790  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Task</th>\n      <th>Model</th>\n      <th>LO(E)</th>\n      <th>Mean Plan Context</th>\n      <th>Mean Beliefs</th>\n      <th>Inferences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>find-non-living-thing</td>\n      <td>MiniLM L6</td>\n      <td>0.640000</td>\n      <td>4.200000</td>\n      <td>7.840000</td>\n      <td>1076</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>melt</td>\n      <td>MiniLM L6</td>\n      <td>1.347826</td>\n      <td>4.826087</td>\n      <td>10.956522</td>\n      <td>691</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>find-non-living-thing</td>\n      <td>Bert Base</td>\n      <td>0.600000</td>\n      <td>4.160000</td>\n      <td>8.400000</td>\n      <td>1075</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>melt</td>\n      <td>Bert Base</td>\n      <td>1.160000</td>\n      <td>4.800000</td>\n      <td>11.120000</td>\n      <td>690</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>find-non-living-thing</td>\n      <td>Roberta Large</td>\n      <td>0.407407</td>\n      <td>4.185185</td>\n      <td>7.296296</td>\n      <td>1076</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>melt</td>\n      <td>Roberta Large</td>\n      <td>1.218750</td>\n      <td>5.250000</td>\n      <td>11.062500</td>\n      <td>790</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write_df = statistics_df.loc[:, ['task', 'model', 'mean_entailment_lexical_overlap', 'mean_h', 'mean_p', 'num_entailment', 'num_nonentailment']]\n",
    "write_nli_df = statistics_df.loc[:,\n",
    "               ['task', 'model', 'mean_entailment_lexical_overlap', 'mean_h', 'mean_p', 'num_inferences']]\n",
    "write_nli_df = write_nli_df.replace('MoritzLaurer/MiniLM-L6-mnli', 'MiniLM L6')\n",
    "write_nli_df = write_nli_df.replace('roberta-large-mnli', 'Roberta Large')\n",
    "write_nli_df = write_nli_df.replace('gchhablani/bert-base-cased-finetuned-mnli', 'Bert Base')\n",
    "write_nli_df.rename(columns={\n",
    "    'task': 'Task',\n",
    "    'model': 'Model',\n",
    "    'mean_entailment_lexical_overlap': \"LO(E)\",\n",
    "    'mean_h': 'Mean Plan Context',\n",
    "    'mean_p': 'Mean Beliefs',\n",
    "    'num_inferences': 'Inferences'\n",
    "}, inplace=True)\n",
    "\n",
    "write_nli_df[['Task', 'Model', 'LO(E)', 'Mean Beliefs', 'Mean Plan Context', 'Inferences']].sort_values(\n",
    "    ['Task', 'Model']).to_csv(\"nli_inference_results.csv\", index=False, float_format='%.3f')\n",
    "write_nli_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T08:51:11.236329Z",
     "end_time": "2023-10-09T08:51:11.270585Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "           Model  Params  MNLI-m                   Task     Score  BDI Score  \\\n0      MiniLM L6      22    82.2  find-non-living-thing  0.885333   0.689333   \n3      MiniLM L6      22    82.2                   melt  0.262222   0.233333   \n1      Bert Base     110    84.6  find-non-living-thing  0.937200   0.842800   \n4      Bert Base     110    84.6                   melt  0.362222   0.333333   \n2  Roberta Large     355    90.8  find-non-living-thing  0.980000   0.980000   \n5  Roberta Large     355    90.8                   melt  0.676667   0.673333   \n\n   Num Actions    Errors  Num Plans     LO(E)  Mean Beliefs  \\\n0     7.653333  0.373333   2.573333  6.960000      7.840000   \n3     8.777778  1.000000   3.555556  8.913043     10.956522   \n1     9.613333  0.200000   2.720000  7.560000      8.400000   \n4    11.444444  0.666667   3.555556  9.280000     11.120000   \n2     9.186667  0.080000   2.840000  6.851852      7.296296   \n5    20.888889  0.333333   5.666667  9.218750     11.062500   \n\n   Mean Plan Context  Inferences  \n0           4.200000        1076  \n3           4.826087         691  \n1           4.160000        1075  \n4           4.800000         690  \n2           4.185185        1076  \n5           5.250000         790  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Params</th>\n      <th>MNLI-m</th>\n      <th>Task</th>\n      <th>Score</th>\n      <th>BDI Score</th>\n      <th>Num Actions</th>\n      <th>Errors</th>\n      <th>Num Plans</th>\n      <th>LO(E)</th>\n      <th>Mean Beliefs</th>\n      <th>Mean Plan Context</th>\n      <th>Inferences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MiniLM L6</td>\n      <td>22</td>\n      <td>82.2</td>\n      <td>find-non-living-thing</td>\n      <td>0.885333</td>\n      <td>0.689333</td>\n      <td>7.653333</td>\n      <td>0.373333</td>\n      <td>2.573333</td>\n      <td>6.960000</td>\n      <td>7.840000</td>\n      <td>4.200000</td>\n      <td>1076</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MiniLM L6</td>\n      <td>22</td>\n      <td>82.2</td>\n      <td>melt</td>\n      <td>0.262222</td>\n      <td>0.233333</td>\n      <td>8.777778</td>\n      <td>1.000000</td>\n      <td>3.555556</td>\n      <td>8.913043</td>\n      <td>10.956522</td>\n      <td>4.826087</td>\n      <td>691</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bert Base</td>\n      <td>110</td>\n      <td>84.6</td>\n      <td>find-non-living-thing</td>\n      <td>0.937200</td>\n      <td>0.842800</td>\n      <td>9.613333</td>\n      <td>0.200000</td>\n      <td>2.720000</td>\n      <td>7.560000</td>\n      <td>8.400000</td>\n      <td>4.160000</td>\n      <td>1075</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bert Base</td>\n      <td>110</td>\n      <td>84.6</td>\n      <td>melt</td>\n      <td>0.362222</td>\n      <td>0.333333</td>\n      <td>11.444444</td>\n      <td>0.666667</td>\n      <td>3.555556</td>\n      <td>9.280000</td>\n      <td>11.120000</td>\n      <td>4.800000</td>\n      <td>690</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Roberta Large</td>\n      <td>355</td>\n      <td>90.8</td>\n      <td>find-non-living-thing</td>\n      <td>0.980000</td>\n      <td>0.980000</td>\n      <td>9.186667</td>\n      <td>0.080000</td>\n      <td>2.840000</td>\n      <td>6.851852</td>\n      <td>7.296296</td>\n      <td>4.185185</td>\n      <td>1076</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Roberta Large</td>\n      <td>355</td>\n      <td>90.8</td>\n      <td>melt</td>\n      <td>0.676667</td>\n      <td>0.673333</td>\n      <td>20.888889</td>\n      <td>0.333333</td>\n      <td>5.666667</td>\n      <td>9.218750</td>\n      <td>11.062500</td>\n      <td>5.250000</td>\n      <td>790</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.64num_params = {\n",
    "    'Bert Base': 110,\n",
    "    'Roberta Large': 355,\n",
    "    'MiniLM L6': 22\n",
    "}\n",
    "\n",
    "# mnli - m\n",
    "mnli_results = {\n",
    "    'Bert Base': 84.6,\n",
    "    'Roberta Large': 90.8,\n",
    "    'MiniLM L6': 82.2\n",
    "}\n",
    "\n",
    "all_write_df = pd.merge(write_df, write_nli_df, on=['Model', 'Task'], how='inner')\n",
    "columns = ['Model', 'Params', 'MNLI-m', 'Task', 'Score', 'BDI Score', 'Num Actions', 'Errors',\n",
    "           'Num Plans', 'LO(E)', 'Mean Beliefs', 'Mean Plan Context',\n",
    "           'Inferences']\n",
    "all_write_df['Params'] = all_write_df['Model'].apply(lambda model: num_params[model])\n",
    "all_write_df['MNLI-m'] = all_write_df['Model'].apply(lambda model: mnli_results[model])\n",
    "all_write_df = all_write_df[columns].sort_values(['Params','Model', 'Task'])\n",
    "all_write_df.to_csv(\"nli_results.csv\", index=False, float_format='%.3f')\n",
    "all_write_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T10:58:04.326546Z",
     "end_time": "2023-10-08T10:58:04.344280Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Não sei se faz sentido manter a qtd de entailment/non entailment, não tem muito o que falar disso. talvez falar alto nivel em future work\n",
    "\n",
    "We compute the lexical overlap to measure the inference difficult between the belief base and plan context that we manually developed in order to evaluate our approach.\n",
    "Specifically, given a sentence pair consisting in a belief and a context, we calculate the number of words contained in beliefs that are absent in plan context.\n",
    "In cases where lexical overlap is high between the premise and hypothesis, the inference tends to easily infer entailment relation since both sentences are similar and may express the same idea.\n",
    "Hence, in such cases, sophisticated language models exploit shallow syntactic heuristics to infer logical entailment between sentences. (citar paper HANS)\n",
    "We show that the number of lexical overlap is high when comparing to the average word number in both sentences.\n",
    "The average lexical overlap in entailment sentence pairs is higher than the average number of plan context words since most beliefs contain more words.\n",
    "\n",
    "The number of entailed pairs is significant low since the cartesian product between the belief base and plan contexts tends to generate very unrelated pairs.\n",
    "As future work, we plan to pruning very different sentence pairs in order to reduce the NLI model computation.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Não vale a pena medir ground thruth, pois minilm não gerou todos planos (falhou antes pois não deu sequência nos subgoals seguintes)\n",
    "\n",
    "# na real vale contar quantos falsos entailment e quantos falsos não entailment"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T08:21:39.838846Z",
     "end_time": "2023-10-06T08:21:39.879622Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for task, task_df in filtered_nli_df.groupby(\"task\"):\n",
    "    for model, model_df in task_df.groupby(\"model\"):\n",
    "        gt_df = model_df[['p', 'h', 'inference']]\n",
    "        gt_df['y'] = 1  # temp\n",
    "        gt_df.loc[gt_df['inference'] != 'entailment', 'inference'] = 'non_entailment'\n",
    "        gt_df['model'] = model\n",
    "        gt_df['task'] = task\n",
    "        gt_df.sort_values(['h', 'inference']).to_csv(f\"ground_truth_{task}_{model.replace('/', '-')}.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-07T22:24:18.745078Z",
     "end_time": "2023-10-07T22:24:18.833274Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
