{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-07T11:50:02.976338Z",
     "start_time": "2024-08-07T11:50:02.217311Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sources.fallback_policy.model import QNetwork"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T11:50:04.338309Z",
     "start_time": "2024-08-07T11:50:02.977825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# belief_base -- a1 --> belief_base a2\n",
    "# belief_base -- a2 --> belief_base a3\n",
    "\n",
    "\n",
    "embedding_dim = 768\n",
    "num_belief = 2 + 1 # including cls\n",
    "\n",
    "num_actions = 2\n",
    "num_future_actions = 1\n",
    "\n",
    "cls_belief = torch.randn(1, embedding_dim).unsqueeze(0)\n",
    "\n",
    "belief_base = torch.randn(num_belief, embedding_dim).unsqueeze(0)\n",
    "belief_base = torch.cat([cls_belief, belief_base], dim=1)\n",
    "\n",
    "next_belief_base_a = torch.randn(num_belief, embedding_dim).unsqueeze(0)\n",
    "next_belief_base_a = torch.cat([cls_belief, next_belief_base_a], dim=1)\n",
    "\n",
    "next_belief_base_b = torch.randn(num_belief, embedding_dim).unsqueeze(0)\n",
    "next_belief_base_b = torch.cat([cls_belief, next_belief_base_b], dim=1)\n",
    "\n",
    "action_a = torch.randn(1, embedding_dim)\n",
    "action_b = torch.randn(1, embedding_dim)\n",
    "action_c = torch.randn(1, embedding_dim)\n",
    "action_d = torch.randn(1, embedding_dim)\n",
    "\n",
    "transition_a = (belief_base, action_a, next_belief_base_a, action_c, 10)\n",
    "transition_b = (belief_base, action_b, next_belief_base_b, action_d, 0)\n",
    "\n",
    "batch_belief_base = torch.cat([transition_a[0], transition_b[0]]).to('cuda')\n",
    "batch_action = torch.cat([transition_a[1], transition_b[1]]).to('cuda')\n",
    "batch_next_belief_base = torch.cat([transition_a[2], transition_b[2]]).to('cuda')\n",
    "batch_next_actions = torch.cat([transition_a[3], transition_b[3]]).to('cuda')\n",
    "batch_reward = torch.tensor([transition_a[4], transition_b[4]], dtype=torch.float).to('cuda')\n",
    "batch_reward"
   ],
   "id": "11f2c57cc44f37f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  0.], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T11:50:04.381607Z",
     "start_time": "2024-08-07T11:50:04.339723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "network = QNetwork(embedding_dim, embedding_dim, n_blocks=1)\n",
    "network = network.to('cuda')\n",
    "network"
   ],
   "id": "b58f23932a3d148a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNetwork(\n",
       "  (belief_base_encoder): BeliefBaseEncoder(\n",
       "    (blocks): ModuleList(\n",
       "      (0): BeliefTransformerBlock(\n",
       "        (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (qkv_proj_layer): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (mlp): PositionWiseFF(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hidden): Linear(in_features=1536, out_features=768, bias=False)\n",
       "  (q_value_layer): Linear(in_features=768, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T11:50:10.002485Z",
     "start_time": "2024-08-07T11:50:04.383477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# q-learning \n",
    "GAMMA = 0.99\n",
    "\n",
    "num_parameters = sum(p.numel() for p in network.parameters())\n",
    "print(num_parameters)\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    # Q(s', a')\n",
    "    next_q_values = network(belief_base=batch_next_belief_base, belief_base_sizes=[num_belief], action_tensors=batch_next_actions)\n",
    "    #print(next_q_values.size())\n",
    "    # best action of the next state\n",
    "    #next_q_values = torch.tensor([v.max() for v in next_q_values])\n",
    "    best_next_q_values, _ = next_q_values.max(dim=0)\n",
    "    targets = batch_reward  + (GAMMA * best_next_q_values)\n",
    "    \n",
    "    # Q(s, a)\n",
    "    q_values = network(belief_base=batch_belief_base, belief_base_sizes=[num_belief], action_tensors=batch_action)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"[{epoch}] q-values {q_values.squeeze(-1)}, targets {targets.squeeze(-1)}\")\n",
    "    loss = F.smooth_l1_loss(q_values.squeeze(-1), targets.detach())\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(network.parameters(), 1.)\n",
    "    optimizer.step()\n",
    "    #break"
   ],
   "id": "b8eabda64b491d76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7670016\n",
      "[0] q-values tensor([-0.0533, -0.1886], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([10.1080,  0.1080], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[100] q-values tensor([10.1696,  0.0918], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([10.0299,  0.0299], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[200] q-values tensor([10.1762,  0.0989], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([10.0341,  0.0341], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[300] q-values tensor([10.0364,  0.0375], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([10.0379,  0.0379], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[400] q-values tensor([10.0378,  0.0378], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([10.0378,  0.0378], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[500] q-values tensor([10.1754,  0.1147], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([10.0413,  0.0413], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[600] q-values tensor([10.0491,  0.0490], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([10.0484,  0.0484], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[700] q-values tensor([10.0485,  0.0485], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([10.0485,  0.0485], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[800] q-values tensor([10.0485,  0.0485], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([10.0485,  0.0485], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[900] q-values tensor([10.0170,  0.0398], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([10.0513,  0.0513], device='cuda:0', grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T11:50:10.005696Z",
     "start_time": "2024-08-07T11:50:10.003577Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e4d204c60e97bc0e",
   "outputs": [],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
